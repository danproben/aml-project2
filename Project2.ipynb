{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m0/h738qz797blc7sk_ksq12q7c0000gn/T/ipykernel_11231/1306085271.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "135\n",
      "accuracy for test ......  67.64705882352942\n",
      "accuracy for test ......  66.17647058823529\n",
      "accuracy for test ......  70.58823529411765\n",
      "accuracy for test ......  67.64705882352942\n",
      "accuracy for test ......  70.58823529411765\n",
      "accuracy for test ......  64.70588235294117\n",
      "accuracy for test ......  69.11764705882352\n",
      "accuracy for test ......  72.05882352941177\n",
      "accuracy for test ......  70.58823529411765\n",
      "accuracy for test ......  82.35294117647058\n",
      "* Average accuracy *:  70.14705882352942\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_df = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "strokes = data_df[data_df[\"stroke\"] == 1]\n",
    "noStrokes = data_df[data_df[\"stroke\"] == 2]\n",
    "\n",
    "noStrokes = noStrokes.dropna()\n",
    "\n",
    "# Fill missing data in MIs using the imputer method considering 5 neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(strokes)\n",
    "imputed_data = imputer.transform(strokes)\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=strokes.columns)\n",
    "\n",
    "undersample_noStrokes = noStrokes.sample(frac=0.097)\n",
    "\n",
    "print(len(undersample_noStrokes))\n",
    "print(len(strokes))\n",
    "\n",
    "# combine datasets\n",
    "# Ignore index to concatenate to the appropriate axis\n",
    "data = pd.concat([imputed_df, undersample_noStrokes], ignore_index=True)\n",
    "\n",
    "X = data[['Sex', 'Age', 'Race', 'Diastolic', 'Systolic', 'Pulse', 'BMI', 'HDL', 'Trig', 'LDL', 'TCHOL', 'kidneys_eGFR', 'Diabetes', 'CurrentSmoker', 'isActive']]\n",
    "y = data[\"stroke\"]\n",
    "\n",
    "avgAccuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y) \n",
    "    # n_estimators = 100 <--- # of trees\n",
    "    \n",
    "    # Create a Gradient Boosting classifier with regularization\n",
    "    gbt = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    # Fit the model to the data\n",
    "    gbt.fit(X_train, y_train)\n",
    "    \n",
    "    #print(\"accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "    acc = gbt.score(X_test, y_test)*100\n",
    "    avgAccuracy = avgAccuracy+[acc]\n",
    "    print(\"accuracy for test ...... \", acc)\n",
    "\n",
    "print(\"* Average accuracy *: \", sum(avgAccuracy)/len(avgAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "135\n",
      "accuracy for test ......  70.58823529411765\n",
      "accuracy for test ......  66.17647058823529\n",
      "accuracy for test ......  75.0\n",
      "accuracy for test ......  70.58823529411765\n",
      "accuracy for test ......  72.05882352941177\n",
      "accuracy for test ......  61.76470588235294\n",
      "accuracy for test ......  72.05882352941177\n",
      "accuracy for test ......  79.41176470588235\n",
      "accuracy for test ......  75.0\n",
      "accuracy for test ......  72.05882352941177\n",
      "* Average accuracy *:  71.47058823529412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "strokes = data_df[data_df[\"stroke\"] == 1]\n",
    "noStrokes = data_df[data_df[\"stroke\"] == 2]\n",
    "\n",
    "noStrokes = noStrokes.dropna()\n",
    "\n",
    "# Fill missing data in MIs using the imputer method considering 5 neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(strokes)\n",
    "imputed_data = imputer.transform(strokes)\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=strokes.columns)\n",
    "\n",
    "undersample_noStrokes = noStrokes.sample(frac=0.097)\n",
    "\n",
    "print(len(undersample_noStrokes))\n",
    "print(len(strokes))\n",
    "\n",
    "# combine datasets\n",
    "# Ignore index to concatenate to the appropriate axis\n",
    "data = pd.concat([imputed_df, undersample_noStrokes], ignore_index=True)\n",
    "\n",
    "X = data[['Sex', 'Age', 'Race', 'Diastolic', 'Systolic', 'Pulse', 'BMI', 'HDL', 'Trig', 'LDL', 'TCHOL', 'kidneys_eGFR', 'Diabetes', 'CurrentSmoker', 'isActive']]\n",
    "y = data[\"stroke\"]\n",
    "\n",
    "avgAccuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, stratify=y) \n",
    "    # n_estimators = 100 <--- # of trees\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, criterion='gini', random_state=25)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #print(\"accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "    acc = clf.score(X_test, y_test)*100\n",
    "    avgAccuracy = avgAccuracy+[acc]\n",
    "    print(\"accuracy for test ...... \", acc)\n",
    "\n",
    "print(\"* Average accuracy *: \", sum(avgAccuracy)/len(avgAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m0/h738qz797blc7sk_ksq12q7c0000gn/T/ipykernel_20350/3914447182.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "135\n",
      "accuracy train :  0.7936507936507936\n",
      "accuracy test :  0.6829268292682927\n",
      "predicted probabilities:\n",
      " [[0.634 0.366]\n",
      " [0.051 0.949]\n",
      " [0.155 0.845]\n",
      " [0.940 0.060]\n",
      " [0.053 0.947]\n",
      " [0.789 0.211]\n",
      " [0.050 0.950]\n",
      " [0.393 0.607]\n",
      " [0.041 0.959]\n",
      " [0.017 0.983]\n",
      " [0.627 0.373]\n",
      " [0.356 0.644]\n",
      " [0.013 0.987]\n",
      " [0.759 0.241]\n",
      " [0.088 0.912]\n",
      " [0.236 0.764]\n",
      " [0.087 0.913]\n",
      " [0.143 0.857]\n",
      " [0.544 0.456]\n",
      " [0.738 0.262]\n",
      " [0.459 0.541]\n",
      " [0.381 0.619]\n",
      " [0.955 0.045]\n",
      " [0.848 0.152]\n",
      " [0.161 0.839]\n",
      " [0.568 0.432]\n",
      " [0.607 0.393]\n",
      " [0.810 0.190]\n",
      " [0.314 0.686]\n",
      " [0.460 0.540]\n",
      " [0.653 0.347]\n",
      " [0.534 0.466]\n",
      " [0.245 0.755]\n",
      " [0.088 0.912]\n",
      " [0.204 0.796]\n",
      " [0.850 0.150]\n",
      " [0.701 0.299]\n",
      " [0.581 0.419]\n",
      " [0.546 0.454]\n",
      " [0.416 0.584]\n",
      " [0.917 0.083]\n",
      " [0.772 0.228]\n",
      " [0.040 0.960]\n",
      " [0.108 0.892]\n",
      " [0.898 0.102]\n",
      " [0.252 0.748]\n",
      " [0.500 0.500]\n",
      " [0.092 0.908]\n",
      " [0.811 0.189]\n",
      " [0.031 0.969]\n",
      " [0.080 0.920]\n",
      " [0.034 0.966]\n",
      " [0.022 0.978]\n",
      " [0.841 0.159]\n",
      " [0.706 0.294]\n",
      " [0.153 0.847]\n",
      " [0.337 0.663]\n",
      " [0.122 0.878]\n",
      " [0.846 0.154]\n",
      " [0.403 0.597]\n",
      " [0.606 0.394]\n",
      " [0.214 0.786]\n",
      " [0.716 0.284]\n",
      " [0.437 0.563]\n",
      " [0.638 0.362]\n",
      " [0.121 0.879]\n",
      " [0.044 0.956]\n",
      " [0.711 0.289]\n",
      " [0.118 0.882]\n",
      " [0.991 0.009]\n",
      " [0.688 0.312]\n",
      " [0.771 0.229]\n",
      " [0.586 0.414]\n",
      " [0.087 0.913]\n",
      " [0.328 0.672]\n",
      " [0.880 0.120]\n",
      " [0.707 0.293]\n",
      " [0.686 0.314]\n",
      " [0.644 0.356]\n",
      " [0.093 0.907]\n",
      " [0.021 0.979]\n",
      " [0.852 0.148]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "data_df = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "strokes = data_df[data_df[\"stroke\"] == 1]\n",
    "noStrokes = data_df[data_df[\"stroke\"] == 2]\n",
    "\n",
    "noStrokes = noStrokes.dropna()\n",
    "\n",
    "# Fill missing data in MIs using the imputer method considering 5 neighbors\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(strokes)\n",
    "imputed_data = imputer.transform(strokes)\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=strokes.columns)\n",
    "\n",
    "undersample_noStrokes = noStrokes.sample(frac=0.097)\n",
    "\n",
    "print(len(undersample_noStrokes))\n",
    "print(len(strokes))\n",
    "\n",
    "# combine datasets\n",
    "# Ignore index to concatenate to the appropriate axis\n",
    "data = pd.concat([imputed_df, undersample_noStrokes], ignore_index=True)\n",
    "\n",
    "X = data[['Sex', 'Age', 'Race', 'Diastolic', 'Systolic', 'Pulse', 'BMI', 'HDL', 'Trig', 'LDL', 'TCHOL', 'kidneys_eGFR', 'Diabetes', 'CurrentSmoker', 'isActive']]\n",
    "y = data[\"stroke\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =  \\\n",
    "        train_test_split(X, y, test_size=.30, random_state=42)\n",
    "\n",
    "# kernals could be: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’.              \n",
    "clf = svm.SVC(kernel=\"linear\", C=1000, probability=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy train : \", clf.score(X_train, y_train))\n",
    "print(\"accuracy test : \", clf.score(X_test, y_test))\n",
    "\n",
    "print(\"predicted probabilities:\\n\", clf.predict_proba(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
